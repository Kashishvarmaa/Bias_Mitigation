{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "from aif360.metrics import ClassificationMetric\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'StudentFeedback_final.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>12th marks %</th>\n",
       "      <th>rural/ urban area</th>\n",
       "      <th>Why take this course?</th>\n",
       "      <th>Which teaching methods helped your learning?</th>\n",
       "      <th>Were you prepared to take this course based on prior coursework?</th>\n",
       "      <th>How much time did you spend weekly on this course outside of class for C01?</th>\n",
       "      <th>How much time did you spend weekly on this course outside of class for C02?</th>\n",
       "      <th>How much time did you spend weekly on this course outside of class for C03?</th>\n",
       "      <th>...</th>\n",
       "      <th>Explain briefly your rationale for you choice to the previous question</th>\n",
       "      <th>Would more faculty concern improve your learning in C01?</th>\n",
       "      <th>Would more faculty concern improve your learning in C02?</th>\n",
       "      <th>Would more faculty concern improve your learning in C03?</th>\n",
       "      <th>Would more faculty concern improve your learning in C04?</th>\n",
       "      <th>Would more outside help improve your learning in C01?</th>\n",
       "      <th>Would more outside help improve your learning in C02?</th>\n",
       "      <th>Would more outside help improve your learning in C03?</th>\n",
       "      <th>Would more outside help improve your learning in C04?</th>\n",
       "      <th>Your overall feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.350515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.123711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.268041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender       Age  12th marks %  rural/ urban area  Why take this course?  \\\n",
       "0     1.0  0.333333      0.350515                1.0               0.388889   \n",
       "1     0.0  1.000000      0.340206                1.0               0.305556   \n",
       "2     1.0  0.666667      0.123711                0.0               0.527778   \n",
       "3     0.0  0.666667      0.268041                1.0               0.083333   \n",
       "4     1.0  0.333333      0.216495                1.0               0.722222   \n",
       "\n",
       "   Which teaching methods helped your learning?  \\\n",
       "0                                      0.608333   \n",
       "1                                      0.516667   \n",
       "2                                      0.383333   \n",
       "3                                      0.316667   \n",
       "4                                      0.600000   \n",
       "\n",
       "   Were you prepared to take this course based on prior coursework?  \\\n",
       "0                                                1.0                  \n",
       "1                                                0.0                  \n",
       "2                                                1.0                  \n",
       "3                                                1.0                  \n",
       "4                                                0.0                  \n",
       "\n",
       "   How much time did you spend weekly on this course outside of class for C01?  \\\n",
       "0                                              0.250                             \n",
       "1                                              0.375                             \n",
       "2                                              0.500                             \n",
       "3                                              0.125                             \n",
       "4                                              0.125                             \n",
       "\n",
       "   How much time did you spend weekly on this course outside of class for C02?  \\\n",
       "0                                              0.250                             \n",
       "1                                              0.500                             \n",
       "2                                              0.500                             \n",
       "3                                              0.125                             \n",
       "4                                              0.125                             \n",
       "\n",
       "   How much time did you spend weekly on this course outside of class for C03?  \\\n",
       "0                                           0.222222                             \n",
       "1                                           0.666667                             \n",
       "2                                           0.555556                             \n",
       "3                                           0.222222                             \n",
       "4                                           0.111111                             \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "4  ...   \n",
       "\n",
       "   Explain briefly your rationale for you choice to the previous question  \\\n",
       "0                                           0.059908                        \n",
       "1                                           0.147465                        \n",
       "2                                           0.525346                        \n",
       "3                                           0.695853                        \n",
       "4                                           0.847926                        \n",
       "\n",
       "   Would more faculty concern improve your learning in C01?  \\\n",
       "0                                                0.0          \n",
       "1                                                0.0          \n",
       "2                                                1.0          \n",
       "3                                                0.0          \n",
       "4                                                0.0          \n",
       "\n",
       "   Would more faculty concern improve your learning in C02?  \\\n",
       "0                                                0.0          \n",
       "1                                                0.0          \n",
       "2                                                1.0          \n",
       "3                                                0.0          \n",
       "4                                                0.0          \n",
       "\n",
       "   Would more faculty concern improve your learning in C03?  \\\n",
       "0                                                0.0          \n",
       "1                                                1.0          \n",
       "2                                                1.0          \n",
       "3                                                0.0          \n",
       "4                                                0.0          \n",
       "\n",
       "   Would more faculty concern improve your learning in C04?  \\\n",
       "0                                                0.0          \n",
       "1                                                1.0          \n",
       "2                                                1.0          \n",
       "3                                                0.0          \n",
       "4                                                0.0          \n",
       "\n",
       "   Would more outside help improve your learning in C01?  \\\n",
       "0                                                0.0       \n",
       "1                                                0.0       \n",
       "2                                                1.0       \n",
       "3                                                0.0       \n",
       "4                                                0.0       \n",
       "\n",
       "   Would more outside help improve your learning in C02?  \\\n",
       "0                                                0.0       \n",
       "1                                                0.0       \n",
       "2                                                1.0       \n",
       "3                                                0.0       \n",
       "4                                                0.0       \n",
       "\n",
       "   Would more outside help improve your learning in C03?  \\\n",
       "0                                                0.0       \n",
       "1                                                1.0       \n",
       "2                                                1.0       \n",
       "3                                                0.0       \n",
       "4                                                0.0       \n",
       "\n",
       "   Would more outside help improve your learning in C04?  \\\n",
       "0                                                0.0       \n",
       "1                                                1.0       \n",
       "2                                                1.0       \n",
       "3                                                0.0       \n",
       "4                                                0.0       \n",
       "\n",
       "   Your overall feedback  \n",
       "0               0.000000  \n",
       "1               0.333333  \n",
       "2               0.000000  \n",
       "3               0.000000  \n",
       "4               0.000000  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Target and Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable (Gender) for gender bias mitigation\n",
    "y = df['Gender']\n",
    "\n",
    "# Define the features by dropping the target column (Gender)\n",
    "X = df.drop(columns=['Gender'])\n",
    "\n",
    "# Specify the sensitive feature for adversarial de-biasing\n",
    "sensitive_feature = 'Gender'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Dataset into AIF360 Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import BinaryLabelDataset\n",
    "\n",
    "# Convert the dataset into AIF360 BinaryLabelDataset format\n",
    "data = BinaryLabelDataset(df=pd.concat([X, y], axis=1),\n",
    "                          label_names=['Gender'],  # Set Gender as the label (target) for bias mitigation\n",
    "                          protected_attribute_names=['Gender'])  # Specify Gender as the sensitive attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train, test = data.split([0.8], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing: Reweighing the Dataset to Mitigate Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\preprocessing\\reweighing.py:67: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  self.w_p_unfav = n_unfav*n_p / (n*n_p_unfav)\n",
      "c:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\preprocessing\\reweighing.py:68: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  self.w_up_fav = n_fav*n_up / (n*n_up_fav)\n"
     ]
    }
   ],
   "source": [
    "reweigher = Reweighing(unprivileged_groups=[{'Gender': 0}], privileged_groups=[{'Gender': 1}])\n",
    "train_reweighed = reweigher.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privileged group (female) count: 33\n",
      "Unprivileged group (male) count: 25\n"
     ]
    }
   ],
   "source": [
    "# Counts for privileged and unprivileged groups\n",
    "print(\"Privileged group (female) count:\", sum(test.protected_attributes[:, 0] == 1))\n",
    "print(\"Unprivileged group (male) count:\", sum(test.protected_attributes[:, 0] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Processing: Adversarial Debiasing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable eager execution (for TensorFlow 2.x users)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Set up the session\n",
    "sess = tf.compat.v1.Session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up and Train the Adversarial Debiasing Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "\n",
    "# Ensure compatibility with TensorFlow 1.x by using tf.compat.v1\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()  # Clear any existing graph\n",
    "\n",
    "# Start a new session\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the AdversarialDebiasing model\n",
    "adv_debiasing = AdversarialDebiasing(privileged_groups=[{'Gender': 1}],   # Privileged group: Female\n",
    "                                     unprivileged_groups=[{'Gender': 0}],  # Unprivileged group: Male\n",
    "                                     scope_name='debiasing_classifier',\n",
    "                                     debias=True,                         # Enable debiasing\n",
    "                                     sess=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.692451; batch adversarial loss: 0.661673\n",
      "epoch 1; iter: 0; batch classifier loss: 0.677980; batch adversarial loss: 0.658386\n",
      "epoch 2; iter: 0; batch classifier loss: 0.692987; batch adversarial loss: 0.659899\n",
      "epoch 3; iter: 0; batch classifier loss: 0.664513; batch adversarial loss: 0.660688\n",
      "epoch 4; iter: 0; batch classifier loss: 0.676909; batch adversarial loss: 0.659652\n",
      "epoch 5; iter: 0; batch classifier loss: 0.700212; batch adversarial loss: 0.658515\n",
      "epoch 6; iter: 0; batch classifier loss: 0.690675; batch adversarial loss: 0.657424\n",
      "epoch 7; iter: 0; batch classifier loss: 0.681590; batch adversarial loss: 0.659232\n",
      "epoch 8; iter: 0; batch classifier loss: 0.684126; batch adversarial loss: 0.658813\n",
      "epoch 9; iter: 0; batch classifier loss: 0.685129; batch adversarial loss: 0.658932\n",
      "epoch 10; iter: 0; batch classifier loss: 0.677112; batch adversarial loss: 0.658635\n",
      "epoch 11; iter: 0; batch classifier loss: 0.672490; batch adversarial loss: 0.657628\n",
      "epoch 12; iter: 0; batch classifier loss: 0.654360; batch adversarial loss: 0.658320\n",
      "epoch 13; iter: 0; batch classifier loss: 0.675472; batch adversarial loss: 0.661745\n",
      "epoch 14; iter: 0; batch classifier loss: 0.656097; batch adversarial loss: 0.657605\n",
      "epoch 15; iter: 0; batch classifier loss: 0.677897; batch adversarial loss: 0.660512\n",
      "epoch 16; iter: 0; batch classifier loss: 0.655776; batch adversarial loss: 0.657907\n",
      "epoch 17; iter: 0; batch classifier loss: 0.665515; batch adversarial loss: 0.659922\n",
      "epoch 18; iter: 0; batch classifier loss: 0.641665; batch adversarial loss: 0.658420\n",
      "epoch 19; iter: 0; batch classifier loss: 0.648506; batch adversarial loss: 0.655208\n",
      "epoch 20; iter: 0; batch classifier loss: 0.644460; batch adversarial loss: 0.658538\n",
      "epoch 21; iter: 0; batch classifier loss: 0.671726; batch adversarial loss: 0.658991\n",
      "epoch 22; iter: 0; batch classifier loss: 0.667743; batch adversarial loss: 0.660449\n",
      "epoch 23; iter: 0; batch classifier loss: 0.660834; batch adversarial loss: 0.657238\n",
      "epoch 24; iter: 0; batch classifier loss: 0.639188; batch adversarial loss: 0.658970\n",
      "epoch 25; iter: 0; batch classifier loss: 0.656215; batch adversarial loss: 0.658635\n",
      "epoch 26; iter: 0; batch classifier loss: 0.649365; batch adversarial loss: 0.664662\n",
      "epoch 27; iter: 0; batch classifier loss: 0.648950; batch adversarial loss: 0.661176\n",
      "epoch 28; iter: 0; batch classifier loss: 0.636139; batch adversarial loss: 0.660769\n",
      "epoch 29; iter: 0; batch classifier loss: 0.645784; batch adversarial loss: 0.657383\n",
      "epoch 30; iter: 0; batch classifier loss: 0.614928; batch adversarial loss: 0.660313\n",
      "epoch 31; iter: 0; batch classifier loss: 0.656576; batch adversarial loss: 0.659150\n",
      "epoch 32; iter: 0; batch classifier loss: 0.634465; batch adversarial loss: 0.658330\n",
      "epoch 33; iter: 0; batch classifier loss: 0.637817; batch adversarial loss: 0.659632\n",
      "epoch 34; iter: 0; batch classifier loss: 0.622131; batch adversarial loss: 0.662848\n",
      "epoch 35; iter: 0; batch classifier loss: 0.627381; batch adversarial loss: 0.660820\n",
      "epoch 36; iter: 0; batch classifier loss: 0.620828; batch adversarial loss: 0.662842\n",
      "epoch 37; iter: 0; batch classifier loss: 0.649266; batch adversarial loss: 0.661801\n",
      "epoch 38; iter: 0; batch classifier loss: 0.646364; batch adversarial loss: 0.661378\n",
      "epoch 39; iter: 0; batch classifier loss: 0.634677; batch adversarial loss: 0.663683\n",
      "epoch 40; iter: 0; batch classifier loss: 0.652078; batch adversarial loss: 0.662220\n",
      "epoch 41; iter: 0; batch classifier loss: 0.646068; batch adversarial loss: 0.661201\n",
      "epoch 42; iter: 0; batch classifier loss: 0.608173; batch adversarial loss: 0.660542\n",
      "epoch 43; iter: 0; batch classifier loss: 0.611178; batch adversarial loss: 0.660107\n",
      "epoch 44; iter: 0; batch classifier loss: 0.624253; batch adversarial loss: 0.666109\n",
      "epoch 45; iter: 0; batch classifier loss: 0.633755; batch adversarial loss: 0.664080\n",
      "epoch 46; iter: 0; batch classifier loss: 0.616684; batch adversarial loss: 0.664051\n",
      "epoch 47; iter: 0; batch classifier loss: 0.632972; batch adversarial loss: 0.665083\n",
      "epoch 48; iter: 0; batch classifier loss: 0.604941; batch adversarial loss: 0.661925\n",
      "epoch 49; iter: 0; batch classifier loss: 0.597349; batch adversarial loss: 0.665354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x1c39081b920>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "adv_debiasing.fit(train_reweighed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions with the Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "predictions = adv_debiasing.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions.labels)  # This should show the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = test.copy()\n",
    "predicted_data.labels = predictions.labels  # Assign the predicted labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.5\n",
      "Statistical Parity Difference: -0.10181818181818182\n",
      "Disparate Impact: 0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Step 1: Ensure 'predicted_data' has updated labels\n",
    "predicted_data = test.copy(deepcopy=True)\n",
    "predicted_data.labels = predictions.labels  # Assuming 'predictions' is the output from adversarial_debiasing.predict(test_data)\n",
    "\n",
    "# Step 2: Calculate accuracy\n",
    "accuracy = accuracy_score(test.labels, predicted_data.labels)\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "\n",
    "# Step 3: Set up fairness evaluation\n",
    "metric = ClassificationMetric(\n",
    "    test,\n",
    "    predicted_data,\n",
    "    privileged_groups=[{'Gender': 1}],  \n",
    "    unprivileged_groups=[{'Gender': 0}], \n",
    ")\n",
    "\n",
    "# Step 4: Calculate fairness metrics\n",
    "stat_parity_diff = metric.statistical_parity_difference()\n",
    "disparate_impact = metric.disparate_impact()\n",
    "\n",
    "# Display results\n",
    "print(\"Statistical Parity Difference:\", stat_parity_diff)\n",
    "print(\"Disparate Impact:\", disparate_impact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privileged group (female) count: 33\n",
      "Unprivileged group (male) count: 25\n"
     ]
    }
   ],
   "source": [
    "# Counts for privileged and unprivileged groups\n",
    "print(\"Privileged group (female) count:\", sum(test.protected_attributes[:, 0] == 1))\n",
    "print(\"Unprivileged group (male) count:\", sum(test.protected_attributes[:, 0] == 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model's Fairness and Performance after In Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "test_labels = test.labels\n",
    "pred_labels = predictions.labels\n",
    "\n",
    "accuracy = accuracy_score(test_labels, pred_labels)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Pre Post-processing): 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy_pre = accuracy_score(test.labels, predictions.labels)\n",
    "print(f\"Test Accuracy (Pre Post-processing): {accuracy_pre:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Compute fairness metrics\n",
    "metric = ClassificationMetric(test, predictions,\n",
    "                              unprivileged_groups=[{'Gender': 0}],\n",
    "                              privileged_groups=[{'Gender': 1}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fairness: Disparate Impact and Equal Opportunity Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (288, 44)\n",
      "Predicted data shape: (58, 44)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data shape:\", data.features.shape)\n",
    "print(\"Predicted data shape:\", predicted_data.features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data features shape: (58, 44)\n",
      "predicted_data features shape: (58, 44)\n",
      "Feature match: False\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(\"data features shape:\", data.features.shape)\n",
    "print(\"predicted_data features shape:\", predicted_data.features.shape)\n",
    "\n",
    "# Check for any feature discrepancies\n",
    "print(\"Feature match:\", np.array_equal(data.features, predicted_data.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact: 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The two datasets are expected to differ only in 'labels' or 'scores'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisparate Impact: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisparate_impact_pre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Step 2: Equal Opportunity Difference with ClassificationMetric (requires both original and predicted datasets)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m classification_metric \u001b[38;5;241m=\u001b[39m \u001b[43mClassificationMetric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# Original dataset\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredicted_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Dataset with predictions\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprivileged_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m equal_opportunity_pre \u001b[38;5;241m=\u001b[39m classification_metric\u001b[38;5;241m.\u001b[39mequal_opportunity_difference()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEqual Opportunity Difference: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mequal_opportunity_pre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\metrics\\classification_metric.py:67\u001b[0m, in \u001b[0;36mClassificationMetric.__init__\u001b[1;34m(self, dataset, classified_dataset, unprivileged_groups, privileged_groups)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtemporarily_ignore(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassified_dataset:\n\u001b[1;32m---> 67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe two datasets are expected to differ only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The two datasets are expected to differ only in 'labels' or 'scores'."
     ]
    }
   ],
   "source": [
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "\n",
    "# Step 1: Disparate Impact with BinaryLabelDatasetMetric (using original data only)\n",
    "metric_pre = BinaryLabelDatasetMetric(\n",
    "    data,  # Use only the original dataset\n",
    "    unprivileged_groups=[{'Gender': 0}],\n",
    "    privileged_groups=[{'Gender': 1}]\n",
    ")\n",
    "disparate_impact_pre = metric_pre.disparate_impact()\n",
    "print(f\"Disparate Impact: {disparate_impact_pre}\")\n",
    "\n",
    "# Step 2: Equal Opportunity Difference with ClassificationMetric (requires both original and predicted datasets)\n",
    "classification_metric = ClassificationMetric(\n",
    "    data,\n",
    "    predicted_data,\n",
    "    unprivileged_groups=[{'Gender': 0}],\n",
    "    privileged_groups=[{'Gender': 1}]\n",
    ")\n",
    "equal_opportunity_pre = classification_metric.equal_opportunity_difference()\n",
    "print(f\"Equal Opportunity Difference: {equal_opportunity_pre}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BinaryLabelDatasetMetric' object has no attribute 'true_positive_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m disparate_impact_pre \u001b[38;5;241m=\u001b[39m metric_pre\u001b[38;5;241m.\u001b[39mdisparate_impact()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Manually calculate the Equal Opportunity Difference\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m tpr_privileged_pre \u001b[38;5;241m=\u001b[39m metric_pre\u001b[38;5;241m.\u001b[39mtrue_positive_rate()\n\u001b[1;32m     14\u001b[0m tpr_unprivileged_pre \u001b[38;5;241m=\u001b[39m metric_pre\u001b[38;5;241m.\u001b[39mtrue_positive_rate()\n\u001b[1;32m     15\u001b[0m equal_opportunity_pre \u001b[38;5;241m=\u001b[39m tpr_privileged_pre \u001b[38;5;241m-\u001b[39m tpr_unprivileged_pre\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BinaryLabelDatasetMetric' object has no attribute 'true_positive_rate'"
     ]
    }
   ],
   "source": [
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "# Assuming 'data' is your original dataset in AIF360's BinaryLabelDataset format\n",
    "# Calculate metrics for the original dataset\n",
    "metric_pre = BinaryLabelDatasetMetric(data,\n",
    "                                       unprivileged_groups=[{'Gender': 0}],  # Unprivileged group: Male\n",
    "                                       privileged_groups=[{'Gender': 1}])    # Privileged group: Female\n",
    "\n",
    "# Calculate metrics before debiasing\n",
    "disparate_impact_pre = metric_pre.disparate_impact()\n",
    "\n",
    "# Manually calculate the Equal Opportunity Difference\n",
    "tpr_privileged_pre = metric_pre.true_positive_rate()\n",
    "tpr_unprivileged_pre = metric_pre.true_positive_rate()\n",
    "equal_opportunity_pre = tpr_privileged_pre - tpr_unprivileged_pre\n",
    "\n",
    "print(f\"Disparate Impact (Pre Post-processing): {disparate_impact_pre}\")\n",
    "print(f\"Equal Opportunity Difference (Pre Post-processing): {equal_opportunity_pre}\")\n",
    "\n",
    "# After applying debiasing, use the predictions to calculate the same metrics\n",
    "# Assuming `predictions` is the predicted output from your debiased model\n",
    "predicted_dataset = data.copy()  # Create a copy of the original dataset\n",
    "predicted_dataset.labels = predictions  # Replace the labels with your model's predictions\n",
    "\n",
    "# Calculate metrics for the predicted dataset\n",
    "metric_post = BinaryLabelDatasetMetric(predicted_dataset,\n",
    "                                        unprivileged_groups=[{'Gender': 0}],  # Unprivileged group: Male\n",
    "                                        privileged_groups=[{'Gender': 1}])    # Privileged group: Female\n",
    "\n",
    "# Calculate metrics after debiasing\n",
    "disparate_impact_post = metric_post.disparate_impact()\n",
    "\n",
    "# Manually calculate the Equal Opportunity Difference for the post-processed dataset\n",
    "tpr_privileged_post = metric_post.true_positive_rate()\n",
    "tpr_unprivileged_post = metric_post.true_positive_rate()\n",
    "equal_opportunity_post = tpr_privileged_post - tpr_unprivileged_post\n",
    "\n",
    "print(f\"Disparate Impact (Post Post-processing): {disparate_impact_post}\")\n",
    "print(f\"Equal Opportunity Difference (Post Post-processing): {equal_opportunity_post}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Difference: nan\n",
      "Equal Opportunity Difference: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kashishvarmaa/Documents/5 Sem/DL/Bias_Mitigation/.conda/lib/python3.11/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/kashishvarmaa/Documents/5 Sem/DL/Bias_Mitigation/.conda/lib/python3.11/site-packages/aif360/metrics/classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
      "/Users/kashishvarmaa/Documents/5 Sem/DL/Bias_Mitigation/.conda/lib/python3.11/site-packages/aif360/metrics/classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n"
     ]
    }
   ],
   "source": [
    "# Demographic parity\n",
    "print(f\"Demographic Parity Difference: {metric.disparate_impact()}\")\n",
    "\n",
    "# Equal opportunity difference\n",
    "print(f\"Equal Opportunity Difference: {metric.equal_opportunity_difference()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing - Equalized Odds Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\metrics\\classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
      "c:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\metrics\\classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n",
      "c:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\postprocessing\\eq_odds_postprocessing.py:177: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (np.mean(oflip*om_tp) - np.mean(oconst*om_tp)) / obr,\n",
      "c:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\postprocessing\\eq_odds_postprocessing.py:178: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (np.mean(oconst*om_fn) - np.mean(oflip*om_fn)) / obr],\n",
      "c:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\postprocessing\\eq_odds_postprocessing.py:179: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  [(np.mean(sconst*sm_fp) - np.mean(sflip*sm_fp)) / (1-sbr),\n",
      "c:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\postprocessing\\eq_odds_postprocessing.py:180: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (np.mean(sflip*sm_tn) - np.mean(sconst*sm_tn)) / (1-sbr),\n",
      "c:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\postprocessing\\eq_odds_postprocessing.py:184: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  b_eq = [(np.mean(oflip*om_tp) + np.mean(oconst*om_fn)) / obr\n",
      "c:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\postprocessing\\eq_odds_postprocessing.py:187: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  - (np.mean(sflip*sm_fp) + np.mean(sconst*sm_tn)) / (1-sbr)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input for linprog: c must not contain values inf, nan, or None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m eq_odds \u001b[38;5;241m=\u001b[39m EqOddsPostprocessing(privileged_groups\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}], \n\u001b[0;32m      2\u001b[0m                                unprivileged_groups\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m}])\n\u001b[1;32m----> 4\u001b[0m predictions_post \u001b[38;5;241m=\u001b[39m \u001b[43meq_odds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\transformer.py:27\u001b[0m, in \u001b[0;36maddmetadata.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 27\u001b[0m     new_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_dataset, Dataset):\n\u001b[0;32m     29\u001b[0m         new_dataset\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m new_dataset\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\postprocessing\\eq_odds_postprocessing.py:257\u001b[0m, in \u001b[0;36mEqOddsPostprocessing.fit_predict\u001b[1;34m(self, dataset_true, dataset_pred)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_true, dataset_pred):\n\u001b[0;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"fit and predict methods sequentially.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(dataset_pred)\n",
      "File \u001b[1;32mc:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\transformer.py:27\u001b[0m, in \u001b[0;36maddmetadata.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 27\u001b[0m     new_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_dataset, Dataset):\n\u001b[0;32m     29\u001b[0m         new_dataset\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m new_dataset\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\postprocessing\\eq_odds_postprocessing.py:190\u001b[0m, in \u001b[0;36mEqOddsPostprocessing.fit\u001b[1;34m(self, dataset_true, dataset_pred)\u001b[0m\n\u001b[0;32m    184\u001b[0m b_eq \u001b[38;5;241m=\u001b[39m [(np\u001b[38;5;241m.\u001b[39mmean(oflip\u001b[38;5;241m*\u001b[39mom_tp) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(oconst\u001b[38;5;241m*\u001b[39mom_fn)) \u001b[38;5;241m/\u001b[39m obr\n\u001b[0;32m    185\u001b[0m       \u001b[38;5;241m-\u001b[39m (np\u001b[38;5;241m.\u001b[39mmean(sflip\u001b[38;5;241m*\u001b[39msm_tp) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(sconst\u001b[38;5;241m*\u001b[39msm_fn)) \u001b[38;5;241m/\u001b[39m sbr,\n\u001b[0;32m    186\u001b[0m         (np\u001b[38;5;241m.\u001b[39mmean(oflip\u001b[38;5;241m*\u001b[39mom_fp) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(oconst\u001b[38;5;241m*\u001b[39mom_tn)) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mobr)\n\u001b[0;32m    187\u001b[0m       \u001b[38;5;241m-\u001b[39m (np\u001b[38;5;241m.\u001b[39mmean(sflip\u001b[38;5;241m*\u001b[39msm_fp) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(sconst\u001b[38;5;241m*\u001b[39msm_tn)) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39msbr)]\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# Linear program\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_params \u001b[38;5;241m=\u001b[39m \u001b[43mlinprog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_ub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_ub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_eq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA_eq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_eq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_eq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_linprog.py:630\u001b[0m, in \u001b[0;36mlinprog\u001b[1;34m(c, A_ub, b_ub, A_eq, b_eq, bounds, method, callback, options, x0, integrality)\u001b[0m\n\u001b[0;32m    627\u001b[0m     integrality \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_to(integrality, np\u001b[38;5;241m.\u001b[39mshape(c))\n\u001b[0;32m    629\u001b[0m lp \u001b[38;5;241m=\u001b[39m _LPProblem(c, A_ub, b_ub, A_eq, b_eq, bounds, x0, integrality)\n\u001b[1;32m--> 630\u001b[0m lp, solver_options \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_linprog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m tol \u001b[38;5;241m=\u001b[39m solver_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-9\u001b[39m)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;66;03m# Give unmodified problem to HiGHS\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_linprog_util.py:1026\u001b[0m, in \u001b[0;36m_parse_linprog\u001b[1;34m(lp, options, meth)\u001b[0m\n\u001b[0;32m   1023\u001b[0m solver_options, A_ub, A_eq \u001b[38;5;241m=\u001b[39m _check_sparse_inputs(solver_options, meth,\n\u001b[0;32m   1024\u001b[0m                                                   lp\u001b[38;5;241m.\u001b[39mA_ub, lp\u001b[38;5;241m.\u001b[39mA_eq)\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;66;03m# Convert lists to numpy arrays, etc...\u001b[39;00m\n\u001b[1;32m-> 1026\u001b[0m lp \u001b[38;5;241m=\u001b[39m \u001b[43m_clean_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_replace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_ub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_eq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA_eq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lp, solver_options\n",
      "File \u001b[1;32mc:\\Users\\ssrut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_linprog_util.py:306\u001b[0m, in \u001b[0;36m_clean_inputs\u001b[1;34m(lp)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input for linprog: c must be a 1-D array and must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot have more than one non-singleton dimension\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(c)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 306\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    307\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input for linprog: c must not contain values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf, nan, or None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m sparse_lhs \u001b[38;5;241m=\u001b[39m sps\u001b[38;5;241m.\u001b[39missparse(A_eq) \u001b[38;5;129;01mor\u001b[39;00m sps\u001b[38;5;241m.\u001b[39missparse(A_ub)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid input for linprog: c must not contain values inf, nan, or None"
     ]
    }
   ],
   "source": [
    "eq_odds = EqOddsPostprocessing(privileged_groups=[{'Gender': 1}], \n",
    "                               unprivileged_groups=[{'Gender': 0}])\n",
    "\n",
    "predictions_post = eq_odds.fit_predict(test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance and Fairness After Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_post' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy_post \u001b[38;5;241m=\u001b[39m accuracy_score(test\u001b[38;5;241m.\u001b[39mlabels, \u001b[43mpredictions_post\u001b[49m\u001b[38;5;241m.\u001b[39mlabels)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy (Post Post-processing): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_post\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions_post' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy_post = accuracy_score(test.labels, predictions_post.labels)\n",
    "print(f\"Test Accuracy (Post Post-processing): {accuracy_post:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metric_post = ClassificationMetric(test, predictions_post,\n",
    "                                   unprivileged_groups=[{'Gender': 0}],\n",
    "                                   privileged_groups=[{'Gender': 1}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fairness: Disparate Impact and Equal Opportunity Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparate_impact_post = metric_post.disparate_impact()\n",
    "equal_opportunity_post = metric_post.equal_opportunity_difference()\n",
    "\n",
    "print(f\"Disparate Impact (Post Post-processing): {disparate_impact_post}\")\n",
    "print(f\"Equal Opportunity Difference (Post Post-processing): {equal_opportunity_post}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Bias Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Demographic Parity (Disparate Impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGzCAYAAADT4Tb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1jElEQVR4nO3dfXzP5eLH8fd39zM2d7NZv9nEMBSnyUy5OW01pXCicIpNC6cHchcRRbcqCR0djnNqjqKkcEqa3B4OcxMhmptu3IRtJJvbje36/dFj3+Nrw4YZl9fz8fg88r0+1/X5XNdn4/vu+lyf79dhjDECAACwhFtZdwAAAOBqItwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3ADXsfDwcCUmJpZ1N6w1evRoORyOsu5GkaZNmyaHw6Hdu3e7lI8dO1a33nqr3N3d1bhxY0nS2bNnNXToUIWGhsrNzU0dOnS45v0FrieEG9yUCt44LrStWbOmrLtYYidOnNDLL7+s22+/XeXKlVNAQIBatGih6dOn60b5lpWTJ09q9OjRWr58eZn14bXXXtO8efOu6jGXL1/u8vvl7e2toKAgtW7dWq+99poOHTpUrON8/fXXGjp0qO666y4lJyfrtddekyS9//77Gjt2rDp16qR//etfGjhw4FXtP3Cj8SjrDgBl6aWXXlLNmjULldeuXbsMenP5MjIyFBsbq7S0NHXp0kV9+/bV6dOn9dlnnykhIUELFizQjBkz5O7uXtZdvaiTJ0/qxRdflCS1bt261M83cuRIDRs2zKXstddeU6dOnUpl9uPpp5/WnXfeqby8PB06dEirV6/WqFGj9Pbbb+uTTz7RPffc46zbrVs3denSRd7e3s6ypUuXys3NTe+99568vLxcym+55RaNHz/+qvcZuBERbnBTu//++9WkSZOy7sYVS0hIUFpamubOnat27do5y59++mkNGTJEb731lv7whz/o2WefLcNeXlh+fr5yc3Ov+Xk9PDzk4XHt/hls0aKFOnXq5FK2efNm3XffferYsaO+//57Va9eXZLk7u5eKIxmZmbK19fXJdgUlFesWPGq9dMYo9OnT8vX1/eqHRO4lrgtBVzC0aNHlZiYqICAAFWsWFEJCQnatGmTHA6Hpk2b5qzXunXrImcbEhMTFR4e7lL21ltvqXnz5qpSpYp8fX0VFRWlTz/99LL6t2bNGi1cuFCJiYkuwabAmDFjFBERoTfeeEOnTp2SJO3evVsOh0NvvfWWxo8fr7CwMPn6+qpVq1baunVrof6XL19eP/30k+Lj4+Xn56eQkBC99NJLhW53nThxQoMHD1ZoaKi8vb1Vt25dvfXWW4XqORwO9e3bVzNmzFCDBg3k7e2tKVOmKDAwUJL04osvOm/hjB49WlLxr++5Y5s6dapq1aolb29v3XnnnVq/fr1L2/PX3DgcDp04cUL/+te/nOdPTEzUsmXL5HA4NHfu3ELnnzlzphwOh1JTUwvtK45GjRppwoQJOnr0qCZNmuQsP3/NjcPhUHJysk6cOOHsW0GdZcuWadu2bc7ygtt6+fn5mjBhgho0aCAfHx8FBQWpd+/e+u2331z6EB4ergcffFALFy5UkyZN5Ovrq7///e+Sfv/9HzBggPNnWrt2bb3xxhvKz8+/rGsuSdu3b9ejjz6qwMBA+fr6qm7duhoxYoRLnf379+uJJ55QUFCQvL291aBBA73//vuXdY1x82HmBje1rKwsHT582KXM4XCoSpUqkn7/P9j27dvrv//9r/7yl78oMjJSc+fOVUJCwhWdd+LEiWrXrp0ee+wx5ebm6uOPP9Yjjzyi+fPnq23btiU61hdffCFJ6t69e5H7PTw89Oc//1kvvviiVq1apbi4OOe+6dOn69ixY+rTp49Onz6tiRMn6p577tF3332noKAgZ728vDy1adNGzZo105tvvqmUlBSNGjVKZ8+e1UsvvSTp92vVrl07LVu2TElJSWrcuLEWLlyoIUOGaP/+/YVumSxdulSffPKJ+vbtq6pVq6pRo0aaPHmynnrqKf3pT3/Sww8/LEm6/fbbS3Q9CsycOVPHjh1T79695XA49Oabb+rhhx/WTz/9JE9PzyLbfPDBB3ryySfVtGlT9erVS5JUq1YtNWvWTKGhoZoxY4b+9Kc/ubSZMWOGatWqpZiYmMvqpyR16tRJSUlJ+vrrr/Xqq69esG9Tp07VunXr9M9//lOS9Ic//EEffPCBXn31VR0/flxjxoyRJEVGRkqSevfurWnTpqlHjx56+umn9fPPP2vSpEn69ttvtWrVKpfrsGPHDnXt2lW9e/dWz549VbduXZ08eVKtWrXS/v371bt3b9WoUUOrV6/W8OHDdfDgQU2YMMGlj8W55lu2bFGLFi3k6empXr16KTw8XD/++KO++OIL59gzMjLUrFkzZwgODAzUV199paSkJGVnZ2vAgAGXfa1xkzDATSg5OdlIKnLz9vZ21ps3b56RZN58801n2dmzZ02LFi2MJJOcnOwsb9WqlWnVqlWhcyUkJJiwsDCXspMnT7q8zs3NNQ0bNjT33HOPS3lYWJhJSEi46Fg6dOhgJJnffvvtgnXmzJljJJl33nnHGGPMzz//bCQZX19f88svvzjrrV271kgyAwcOdOm/JNOvXz9nWX5+vmnbtq3x8vIyhw4dMsb871q98sorLufu1KmTcTgc5ocffnCWSTJubm5m27ZtLnUPHTpkJJlRo0YVGkNxr2/B2KpUqWKOHDniLP/3v/9tJJkvvvjCWTZq1Chz/j+Dfn5+RV7z4cOHG29vb3P06FFnWWZmpvHw8Ciyv+datmyZkWRmz559wTqNGjUylSpVcr4u+B39+eefXcbq5+dXqG2rVq1MgwYNXMpWrlxpJJkZM2a4lKekpBQqDwsLM5JMSkqKS92XX37Z+Pn5mZ07d7qUDxs2zLi7u5u9e/caY0p2zVu2bGkqVKhg9uzZ43LM/Px855+TkpJM9erVzeHDh13qdOnSxQQEBBT6+wOcj9tSuKm9++67WrRokcv21VdfOfcvWLBAHh4eeuqpp5xl7u7u6tev3xWd99y1DL/99puysrLUokULbdy4scTHOnbsmCSpQoUKF6xTsC87O9ulvEOHDrrlllucr5s2baro6GgtWLCg0DH69u3r/HPB/1Hn5uZq8eLFkn6/Vu7u7nr66add2g0ePFjGGJfrKkmtWrVS/fr1izPEy9K5c2dVqlTJ+bpFixaSpJ9++umyjte9e3fl5OS43D6cNWuWzp49q8cff/zKOiupfPnyzp/l1TB79mwFBATo3nvv1eHDh51bVFSUypcvr2XLlrnUr1mzpuLj4wsdo0WLFqpUqZLLMeLi4pSXl6cVK1a41L/UNT906JBWrFihJ554QjVq1HBpW3B70Bijzz77TA899JCMMS7njY+PV1ZW1mX9PcHNhdtSuKk1bdr0oguK9+zZo+rVq6t8+fIu5XXr1r2i886fP1+vvPKKNm3apJycHGf55XzmSkFwOXbs2AUXlV4oAEVERBSqW6dOHX3yyScuZW5ubrr11lsL1ZPkXBOyZ88ehYSEFDpHwS2SPXv2uJQX9ZTa1XT+m2fBm+75602Kq169errzzjs1Y8YMJSUlSfr9llSzZs2uytN1x48fv2hALaldu3YpKytL1apVK3J/Zmamy+uifh67du3Sli1bnGuhLnWMS13zgpDTsGHDC/b70KFDOnr0qKZOnaqpU6cW67zA+Qg3wFXicDiK/DyZvLw8l9crV65Uu3bt1LJlS/3tb39T9erV5enpqeTkZM2cObPE542MjNS8efO0ZcsWtWzZssg6W7ZskaRSnSkpqZI+iVPc61vgQo+9F3WM4urevbv69++vX375RTk5OVqzZo3LIuDLdebMGe3cufOib/ollZ+fr2rVqmnGjBlF7j8/sBT188jPz9e9996roUOHFnmMgoBb4Gpc84KFyo8//vgF17Zd7jos3DwIN8BFhIWFacmSJTp+/LjL7M2OHTsK1a1UqVKRtzzOn7H47LPP5OPjo4ULF7p8hklycvJl9fHBBx/UmDFjNH369CLDTV5enmbOnKlKlSrprrvuctm3a9euQvV37txZ6Omu/Px8/fTTTy5vZjt37pQkZ92wsDAtXrxYx44dc5mB2L59u3P/pVxs5qq41/dKXawPXbp00aBBg/TRRx/p1KlT8vT0VOfOna/4nJ9++qlOnTpV6LbQlahVq5YWL16su+6667If6a5Vq5aOHz/usgj9ShTM/p3/RN65AgMDVaFCBeXl5V218+Lmw5ob4CIeeOABnT17VpMnT3aW5eXl6a9//WuhurVq1dL27dtdPm128+bNWrVqlUs9d3d3ORwOlxmH3bt3X/an4jZv3lxxcXFKTk7W/PnzC+0fMWKEdu7cqaFDhxZ6k5s3b57279/vfL1u3TqtXbtW999/f6HjnDtDYYzRpEmT5OnpqdjYWEm/X6u8vLxCMxnjx4+Xw+Eo8pjnK1eunKTfHz8+X3Gv75Xy8/Mr8vySVLVqVd1///368MMPNWPGDLVp00ZVq1a9ovNt3rxZAwYMUKVKldSnT58rOta5Hn30UeXl5enll18utO/s2bMXHOP5x0hNTdXChQsL7Tt69KjOnj1boj4FBgaqZcuWev/997V3716XfQWzO+7u7urYsaM+++yzIkNQcT/NGTc3Zm5wU/vqq6+cMwvnat68uW699VY99NBDuuuuuzRs2DDt3r1b9evX15w5c5SVlVWozRNPPKG3335b8fHxSkpKUmZmpqZMmaIGDRq4LORt27at3n77bbVp00Z//vOflZmZqXfffVe1a9d23j4qqenTpys2Nlbt27fXn//8Z7Vo0UI5OTmaM2eOli9frs6dO2vIkCGF2tWuXVt33323nnrqKeXk5GjChAmqUqVKodsQPj4+SklJUUJCgqKjo/XVV1/pyy+/1HPPPee8vfHQQw/pj3/8o0aMGKHdu3erUaNG+vrrr/Xvf/9bAwYMUK1atS45Dl9fX9WvX1+zZs1SnTp1VLlyZTVs2FANGzYs9vW9UlFRUVq8eLHefvtthYSEqGbNmoqOjnbu7969u/OD+IoKDhezcuVKnT59Wnl5efr111+1atUqff755woICNDcuXMVHBx81cbRqlUr9e7dW2PGjNGmTZt03333ydPTU7t27dLs2bM1ceLEQh8oeL4hQ4bo888/14MPPqjExERFRUXpxIkT+u677/Tpp59q9+7dJQ5377zzju6++27dcccd6tWrl2rWrKndu3fryy+/1KZNmyRJr7/+upYtW6bo6Gj17NlT9evX15EjR7Rx40YtXrxYR44cudzLgptFmT2nBZShiz0KrvMe8f71119Nt27djL+/vwkICDDdunUz3377baF6xhjz4YcfmltvvdV4eXmZxo0bm4ULFxb5KPh7771nIiIijLe3t6lXr55JTk4u8rHk4jwKXuDYsWNm9OjRpkGDBsbX19dUqFDB3HXXXWbatGkuj9ka879Hd8eOHWvGjRtnQkNDjbe3t2nRooXZvHmzS92Cx49//PFHc99995ly5cqZoKAgM2rUKJOXl1eoDwMHDjQhISHG09PTREREmLFjxxY6vyTTp0+fIsexevVqExUVZby8vAo9Fl6c63vu2M53/vGKuubbt283LVu2NL6+vkZSoeufk5NjKlWqZAICAsypU6eKHMP5Ch4FL9g8PT1NYGCgadmypXn11VdNZmZmoTZX+ih4galTp5qoqCjn78Rtt91mhg4dag4cOOCsExYWZtq2bVtk+2PHjpnhw4eb2rVrGy8vL1O1alXTvHlz89Zbb5nc3FxjTMmuuTHGbN261fzpT38yFStWND4+PqZu3brm+eefd6mTkZFh+vTpY0JDQ42np6cJDg42sbGxZurUqUX2EziXw5gb5Bv1gOvI7t27VbNmTSUnJ9+Q39pd0P+xY8fqmWeeuWjdxMREffrppzp+/Pg16t317ezZswoJCdFDDz2k9957r6y7A6AIrLkBgBKYN2+eDh06dMFPhAZQ9lhzAwDFsHbtWm3ZskUvv/yy/vCHP6hVq1Zl3SUAF8DMDQAUQ8H3XlWrVk3Tp08v6+4AuAjW3AAAAKswcwMAAKxCuAEAAFa5KRcU5+fn68CBA6pQocJlfVEhAAC49owxOnbsmEJCQuTmduH5mZsy3Bw4cEChoaFl3Q0AAHAZ9u3bp//7v/+74P6bMtwUfKnfvn375O/vX8a9AQAAxZGdna3Q0FCXL+ctyk0ZbgpuRfn7+xNuAAC4wVxqSQkLigEAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGCVaxJu3n33XYWHh8vHx0fR0dFat27dRevPnj1b9erVk4+Pj2677TYtWLDggnX/8pe/yOFwaMKECVe51wAA4EZU6uFm1qxZGjRokEaNGqWNGzeqUaNGio+PV2ZmZpH1V69era5duyopKUnffvutOnTooA4dOmjr1q2F6s6dO1dr1qxRSEhIaQ8DAADcIEo93Lz99tvq2bOnevToofr162vKlCkqV66c3n///SLrT5w4UW3atNGQIUMUGRmpl19+WXfccYcmTZrkUm///v3q16+fZsyYIU9Pz9IeBgAAuEGUarjJzc3Vhg0bFBcX978TurkpLi5OqampRbZJTU11qS9J8fHxLvXz8/PVrVs3DRkyRA0aNLhkP3JycpSdne2yAQAAO5VquDl8+LDy8vIUFBTkUh4UFKT09PQi26Snp1+y/htvvCEPDw89/fTTxerHmDFjFBAQ4NxCQ0NLOBIAAHCjuOGeltqwYYMmTpyoadOmyeFwFKvN8OHDlZWV5dz27dtXyr0EAABlpVTDTdWqVeXu7q6MjAyX8oyMDAUHBxfZJjg4+KL1V65cqczMTNWoUUMeHh7y8PDQnj17NHjwYIWHhxd5TG9vb/n7+7tsAADATqUabry8vBQVFaUlS5Y4y/Lz87VkyRLFxMQU2SYmJsalviQtWrTIWb9bt27asmWLNm3a5NxCQkI0ZMgQLVy4sPQGAwAAbggepX2CQYMGKSEhQU2aNFHTpk01YcIEnThxQj169JAkde/eXbfccovGjBkjSerfv79atWqlcePGqW3btvr444/1zTffaOrUqZKkKlWqqEqVKi7n8PT0VHBwsOrWrVvawwEAANe5Ug83nTt31qFDh/TCCy8oPT1djRs3VkpKinPR8N69e+Xm9r8JpObNm2vmzJkaOXKknnvuOUVERGjevHlq2LBhaXcVAABYwGGMMWXdiWstOztbAQEBysrKYv0NAAA3iOK+f99wT0sBAABcDOEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGCVaxJu3n33XYWHh8vHx0fR0dFat27dRevPnj1b9erVk4+Pj2677TYtWLDAue/MmTN69tlnddttt8nPz08hISHq3r27Dhw4UNrDAAAAN4BSDzezZs3SoEGDNGrUKG3cuFGNGjVSfHy8MjMzi6y/evVqde3aVUlJSfr222/VoUMHdejQQVu3bpUknTx5Uhs3btTzzz+vjRs3as6cOdqxY4fatWtX2kMBAAA3AIcxxpTmCaKjo3XnnXdq0qRJkqT8/HyFhoaqX79+GjZsWKH6nTt31okTJzR//nxnWbNmzdS4cWNNmTKlyHOsX79eTZs21Z49e1SjRo1L9ik7O1sBAQHKysqSv7//ZY4MAABcS8V9/y7VmZvc3Fxt2LBBcXFx/zuhm5vi4uKUmppaZJvU1FSX+pIUHx9/wfqSlJWVJYfDoYoVKxa5PycnR9nZ2S4bAACwU6mGm8OHDysvL09BQUEu5UFBQUpPTy+yTXp6eonqnz59Ws8++6y6du16wRQ3ZswYBQQEOLfQ0NDLGA0AALgR3NBPS505c0aPPvqojDGaPHnyBesNHz5cWVlZzm3fvn3XsJcAAOBa8ijNg1etWlXu7u7KyMhwKc/IyFBwcHCRbYKDg4tVvyDY7NmzR0uXLr3ovTdvb295e3tf5igAAMCNpFRnbry8vBQVFaUlS5Y4y/Lz87VkyRLFxMQU2SYmJsalviQtWrTIpX5BsNm1a5cWL16sKlWqlM4AAADADadUZ24kadCgQUpISFCTJk3UtGlTTZgwQSdOnFCPHj0kSd27d9ctt9yiMWPGSJL69++vVq1aady4cWrbtq0+/vhjffPNN5o6daqk34NNp06dtHHjRs2fP195eXnO9TiVK1eWl5dXaQ8JAABcx0o93HTu3FmHDh3SCy+8oPT0dDVu3FgpKSnORcN79+6Vm9v/JpCaN2+umTNnauTIkXruuecUERGhefPmqWHDhpKk/fv36/PPP5ckNW7c2OVcy5YtU+vWrUt7SAAA4DpW6p9zcz3ic24AALjxXBefcwMAAHCtEW4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKtck3Dz7rvvKjw8XD4+PoqOjta6desuWn/27NmqV6+efHx8dNttt2nBggUu+40xeuGFF1S9enX5+voqLi5Ou3btKs0hAACAG0Sph5tZs2Zp0KBBGjVqlDZu3KhGjRopPj5emZmZRdZfvXq1unbtqqSkJH377bfq0KGDOnTooK1btzrrvPnmm3rnnXc0ZcoUrV27Vn5+foqPj9fp06dLezgAAOA65zDGmNI8QXR0tO68805NmjRJkpSfn6/Q0FD169dPw4YNK1S/c+fOOnHihObPn+8sa9asmRo3bqwpU6bIGKOQkBANHjxYzzzzjCQpKytLQUFBmjZtmrp06VLomDk5OcrJyXG+zs7OVmhoqLKysuTv73+1hwwAAEpBdna2AgICLvn+XaozN7m5udqwYYPi4uL+d0I3N8XFxSk1NbXINqmpqS71JSk+Pt5Z/+eff1Z6erpLnYCAAEVHR1/wmGPGjFFAQIBzCw0NvdKhAQCA61SphpvDhw8rLy9PQUFBLuVBQUFKT08vsk16evpF6xf8tyTHHD58uLKyspzbvn37Lms8AADg+udR1h24Fry9veXt7V3W3QAAANdAqc7cVK1aVe7u7srIyHApz8jIUHBwcJFtgoODL1q/4L8lOSYAALh5lGq48fLyUlRUlJYsWeIsy8/P15IlSxQTE1Nkm5iYGJf6krRo0SJn/Zo1ayo4ONilTnZ2ttauXXvBYwIAgJtHqd+WGjRokBISEtSkSRM1bdpUEyZM0IkTJ9SjRw9JUvfu3XXLLbdozJgxkqT+/furVatWGjdunNq2bauPP/5Y33zzjaZOnSpJcjgcGjBggF555RVFRESoZs2aev755xUSEqIOHTqU9nAAAMB1rtTDTefOnXXo0CG98MILSk9PV+PGjZWSkuJcELx37165uf1vAql58+aaOXOmRo4cqeeee04RERGaN2+eGjZs6KwzdOhQnThxQr169dLRo0d19913KyUlRT4+PqU9HAAAcJ0r9c+5uR4V9zl5AABw/bguPucGAADgWiPcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsUmrh5siRI3rsscfk7++vihUrKikpScePH79om9OnT6tPnz6qUqWKypcvr44dOyojI8O5f/PmzeratatCQ0Pl6+uryMhITZw4sbSGAAAAbkClFm4ee+wxbdu2TYsWLdL8+fO1YsUK9erV66JtBg4cqC+++EKzZ8/Wf/7zHx04cEAPP/ywc/+GDRtUrVo1ffjhh9q2bZtGjBih4cOHa9KkSaU1DAAAcINxGGPM1T5oWlqa6tevr/Xr16tJkyaSpJSUFD3wwAP65ZdfFBISUqhNVlaWAgMDNXPmTHXq1EmStH37dkVGRio1NVXNmjUr8lx9+vRRWlqali5dWuz+ZWdnKyAgQFlZWfL397+MEQIAgGutuO/fpTJzk5qaqooVKzqDjSTFxcXJzc1Na9euLbLNhg0bdObMGcXFxTnL6tWrpxo1aig1NfWC58rKylLlypUv2p+cnBxlZ2e7bAAAwE6lEm7S09NVrVo1lzIPDw9VrlxZ6enpF2zj5eWlihUrupQHBQVdsM3q1as1a9asS97uGjNmjAICApxbaGho8QcDAABuKCUKN8OGDZPD4bjotn379tLqq4utW7eqffv2GjVqlO67776L1h0+fLiysrKc2759+65JHwEAwLXnUZLKgwcPVmJi4kXr3HrrrQoODlZmZqZL+dmzZ3XkyBEFBwcX2S44OFi5ubk6evSoy+xNRkZGoTbff/+9YmNj1atXL40cOfKS/fb29pa3t/cl6wEAgBtficJNYGCgAgMDL1kvJiZGR48e1YYNGxQVFSVJWrp0qfLz8xUdHV1km6ioKHl6emrJkiXq2LGjJGnHjh3au3evYmJinPW2bdume+65RwkJCXr11VdL0n0AAHATKJWnpSTp/vvvV0ZGhqZMmaIzZ86oR48eatKkiWbOnClJ2r9/v2JjYzV9+nQ1bdpUkvTUU09pwYIFmjZtmvz9/dWvXz9Jv6+tkX6/FXXPPfcoPj5eY8eOdZ7L3d29WKGrAE9LAQBw4ynu+3eJZm5KYsaMGerbt69iY2Pl5uamjh076p133nHuP3PmjHbs2KGTJ086y8aPH++sm5OTo/j4eP3tb39z7v/000916NAhffjhh/rwww+d5WFhYdq9e3dpDQUAANxASm3m5nrGzA0AADeeMv2cGwAAgLJCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWKXUws2RI0f02GOPyd/fXxUrVlRSUpKOHz9+0TanT59Wnz59VKVKFZUvX14dO3ZURkZGkXV//fVX/d///Z8cDoeOHj1aCiMAAAA3olILN4899pi2bdumRYsWaf78+VqxYoV69ep10TYDBw7UF198odmzZ+s///mPDhw4oIcffrjIuklJSbr99ttLo+sAAOAG5jDGmKt90LS0NNWvX1/r169XkyZNJEkpKSl64IEH9MsvvygkJKRQm6ysLAUGBmrmzJnq1KmTJGn79u2KjIxUamqqmjVr5qw7efJkzZo1Sy+88IJiY2P122+/qWLFisXuX3Z2tgICApSVlSV/f/8rGywAALgmivv+XSozN6mpqapYsaIz2EhSXFyc3NzctHbt2iLbbNiwQWfOnFFcXJyzrF69eqpRo4ZSU1OdZd9//71eeuklTZ8+XW5uxet+Tk6OsrOzXTYAAGCnUgk36enpqlatmkuZh4eHKleurPT09Au28fLyKjQDExQU5GyTk5Ojrl27auzYsapRo0ax+zNmzBgFBAQ4t9DQ0JINCAAA3DBKFG6GDRsmh8Nx0W379u2l1VcNHz5ckZGRevzxx0vcLisry7nt27evlHoIAADKmkdJKg8ePFiJiYkXrXPrrbcqODhYmZmZLuVnz57VkSNHFBwcXGS74OBg5ebm6ujRoy6zNxkZGc42S5cu1XfffadPP/1UklSwXKhq1aoaMWKEXnzxxSKP7e3tLW9v7+IMEQAA3OBKFG4CAwMVGBh4yXoxMTE6evSoNmzYoKioKEm/B5P8/HxFR0cX2SYqKkqenp5asmSJOnbsKEnasWOH9u7dq5iYGEnSZ599plOnTjnbrF+/Xk888YRWrlypWrVqlWQoAADAUiUKN8UVGRmpNm3aqGfPnpoyZYrOnDmjvn37qkuXLs4npfbv36/Y2FhNnz5dTZs2VUBAgJKSkjRo0CBVrlxZ/v7+6tevn2JiYpxPSp0fYA4fPuw8X0melgIAAPYqlXAjSTNmzFDfvn0VGxsrNzc3dezYUe+8845z/5kzZ7Rjxw6dPHnSWTZ+/Hhn3ZycHMXHx+tvf/tbaXURAABYqFQ+5+Z6x+fcAABw4ynTz7kBAAAoK4QbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBWPsu5AWTDGSJKys7PLuCcAAKC4Ct63C97HL+SmDDfHjh2TJIWGhpZxTwAAQEkdO3ZMAQEBF9zvMJeKPxbKz8/XgQMHVKFCBTkcjrLuDoCrKDs7W6Ghodq3b5/8/f3LujsAriJjjI4dO6aQkBC5uV14Zc1NGW4A2Cs7O1sBAQHKysoi3AA3KRYUAwAAqxBuAACAVQg3AKzi7e2tUaNGydvbu6y7AqCMsOYGAABYhZkbAABgFcINAACwCuEGAABYhXADAACsQrgBLNK6dWsNGDCgrLtx3UtMTFSHDh3KtA/h4eGaMGGC83V6erruvfde+fn5qWLFihcsA3BphBvgCiUmJsrhcBTa2rRpU9ZdK9KpU6c0atQo1alTR97e3qpataoeeeQRbdu2ray75qI0A8jEiRM1bdo05+urFQpHjx7t/Pl7eHioatWqatmypSZMmKCcnByXuuvXr1evXr2cr8ePH6+DBw9q06ZN2rlz5wXLAFzaTfnFmcDV1qZNGyUnJ7uUXY+fs5KTk6O4uDjt3btX48aNU3R0tDIyMjRmzBhFR0dr8eLFatasWZn2MS8vr9S/8+1iX7h3pRo0aKDFixcrPz9fv/76q5YvX65XXnlFH3zwgZYvX64KFSpIkgIDA13a/fjjj4qKilJERMRFy0oqNzdXXl5el90euCEZAFckISHBtG/f/qJ1du7caVq0aGG8vb1NZGSk+frrr40kM3fuXGOMMcuWLTOSzG+//eZs8+233xpJ5ueffzbGGHP48GHTpUsXExISYnx9fU3Dhg3NzJkzXc7TqlUr079//wv24/XXXzcOh8Ns2rTJpTwvL880adLE1K9f3+Tn57uMa/To0aZq1aqmQoUKpnfv3iYnJ8flfH369DF9+vQx/v7+pkqVKmbkyJHOYxhjzJEjR0y3bt1MxYoVja+vr2nTpo3ZuXOnc39ycrIJCAgw//73v01kZKRxd3c3CQkJRpLLtmzZsmJdp4LjpaSkmHr16hk/Pz8THx9vDhw44Gxz7s+sqHP99NNPplatWmbs2LEu16ngXLt27Sry+o4aNco0atSoUHlaWprx8vIyI0aMcJaFhYWZ8ePHO/987vkTEhKKLDPGmN9++80kJSU5fyZ//OMfXX6eBX34xz/+YcLDw43D4ShRu+nTp5uwsDDj7+9vOnfubLKzs5118vLyzBtvvGFq1aplvLy8TGhoqHnllVec+/fu3WseeeQRExAQYCpVqmTatWvn/LkA1xK3pYBSlp+fr4cfflheXl5au3atpkyZomeffbbExzl9+rSioqL05ZdfauvWrerVq5e6deumdevWFfsYM2fO1L333qtGjRq5lLu5uWngwIH6/vvvtXnzZmf5kiVLlJaWpuXLl+ujjz7SnDlz9OKLL7q0/de//iUPDw+tW7dOEydO1Ntvv61//vOfzv2JiYn65ptv9Pnnnys1NVXGGD3wwAM6c+aMs87Jkyf1xhtv6J///Ke2bdumd955R48++qjatGmjgwcP6uDBg2revHmxx3ny5Em99dZb+uCDD7RixQrt3btXzzzzTJF1J06cqJiYGPXs2dN5rho1auiJJ54oNBuXnJysli1bqnbt2sXuiyTVq1dP999/v+bMmVPk/vXr16tNmzZ69NFHdfDgQU2cOLHIMkl65JFHlJmZqa+++kobNmzQHXfcodjYWB05csR5vB9++EGfffaZ5syZo02bNhW73Y8//qh58+Zp/vz5mj9/vv7zn//o9ddfd+4fPny4Xn/9dT3//PP6/vvvNXPmTAUFBUmSzpw5o/j4eFWoUEErV67UqlWrVL58ebVp00a5ubklul7AFSvrdAXc6BISEoy7u7vx8/Nz2V599VVjjDELFy40Hh4eZv/+/c42X331VYlnborStm1bM3jwYOfrS83c+Pj4XHD/xo0bjSQza9Ys57gqV65sTpw44awzefJkU758eZOXl+c8X2RkpMtMzbPPPmsiIyONMb/PWEkyq1atcu4/fPiw8fX1NZ988okx5veZFkmFZpOKmhEr7syNJPPDDz8467z77rsmKCjogscu6rrt37/fuLu7m7Vr1xpjjMnNzTVVq1Y106ZNK/L6GXPhmZuC6+Lr6+t8fe7MjTHGtG/f3jk7c6GylStXGn9/f3P69GmXerVq1TJ///vfnX3w9PQ0mZmZJW5Xrlw5l5maIUOGmOjoaGOMMdnZ2cbb29v84x//KHJ8H3zwgalbt67L70JOTo7x9fU1CxcuLLINUFpYcwNcBX/84x81efJkl7LKlStLktLS0hQaGqqQkBDnvpiYmBKfIy8vT6+99po++eQT7d+/X7m5ucrJyVG5cuVKdBxTgm9cadSokcvxY2JidPz4ce3bt09hYWGSpGbNmrmskYmJidG4ceOUl5entLQ0eXh4KDo62rm/SpUqqlu3rtLS0pxlXl5euv3220s0jospV66catWq5XxdvXp1ZWZmlugYISEhatu2rd5//301bdpUX3zxhXJycvTII49cVp+MMVe8lmjz5s06fvy4qlSp4lJ+6tQp/fjjj87XYWFhLmt6itsuPDzcuSZIcr1uaWlpysnJUWxs7AX79sMPP7i0l36fcTz3HMC1QLgBrgI/P78S36o4l5vb73eIzw0e5962kaSxY8dq4sSJmjBhgm677Tb5+flpwIABJZryr1OnjkuoOFdBeZ06dUra/Svm6+tbrDf+4lwnSfL09HR57XA4ShTqCjz55JPq1q2bxo8fr+TkZHXu3LnEYbJAWlqaataseVltCxw/flzVq1fX8uXLC+0791FxPz+/y2pX1HXLz8+X9PvP6FJ9i4qK0owZMwrtO3/xNFDaCDdAKYuMjNS+fft08OBBVa9eXZK0Zs0alzoF//gfPHhQlSpVkiTnWokCq1atUvv27fX4449L+n0tz86dO1W/fv1i96VLly4aMWKENm/e7LLuJj8/X+PHj1f9+vVdyjdv3qxTp04539jWrFmj8uXLKzQ01Fln7dq1LudYs2aNIiIi5O7ursjISJ09e1Zr1651rpn59ddftWPHjkv228vLS3l5eS5lxblOl6Ooc0nSAw88ID8/P02ePFkpKSlasWLFZR1/+/btSklJ0fDhw6+on3fccYfS09Pl4eGh8PDwUm93roiICPn6+mrJkiV68sknizzHrFmzVK1aNfn7+1/WOYCrhQXFwFWQk5Oj9PR0l+3w4cOSpLi4ONWpU0cJCQnavHmzVq5cqREjRri0r127tkJDQzV69Gjt2rVLX375pcaNG+dSJyIiQosWLdLq1auVlpam3r17KyMjo0T9HDhwoJo2baqHHnpIs2fP1t69e7V+/Xp17NhRaWlpeu+991xmUHJzc5WUlKTvv/9eCxYs0KhRo9S3b1/nDIok7d27V4MGDdKOHTv00Ucf6a9//av69+/v7HP79u3Vs2dP/fe//9XmzZv1+OOP65ZbblH79u0v2tfw8HBt2bJFO3bs0OHDh3XmzJliXafLER4errVr12r37t06fPiwc7bC3d1diYmJGj58uCIiIop1O/Hs2bNKT0/XgQMH9N133+mvf/2rWrVqpcaNG2vIkCFX1M+4uDjFxMSoQ4cO+vrrr7V7926tXr1aI0aM0DfffHPV253Lx8dHzz77rIYOHarp06frxx9/1Jo1a/Tee+9Jkh577DFVrVpV7du318qVK/Xzzz9r+fLlevrpp/XLL79c0biBkiLcAFdBSkqKqlev7rLdfffdkn6/lTJ37lydOnVKTZs21ZNPPqlXX33Vpb2np6c++ugjbd++XbfffrveeOMNvfLKKy51Ro4cqTvuuEPx8fFq3bq1goODS/whdz4+Plq6dKm6d++u5557TrVr11abNm3k7u6uNWvWFPqMm9jYWEVERKhly5bq3Lmz2rVrp9GjR7vU6d69u3Nsffr0Uf/+/V0+nC45OVlRUVF68MEHFRMTI2OMFixYUOgWyPl69uypunXrqkmTJgoMDNSqVauKdZ0uxzPPPCN3d3fVr19fgYGB2rt3r3NfUlKScnNz1aNHj2Ida9u2bapevbpq1Kih1q1b65NPPtHw4cO1cuVKlS9f/or66XA4tGDBArVs2VI9evRQnTp11KVLF+3Zs8f51NLVbHe+559/XoMHD9YLL7ygyMhIde7c2bkmp1y5clqxYoVq1Kihhx9+WJGRkUpKStLp06eZycE15zCXcyMawBVzOByaO3dumX8NwIUkJibq6NGjmjdv3gXrtG7dWo0bN3b5GgHbrFy5UrGxsdq3b1+JggCAssOaGwAoQk5Ojg4dOqTRo0frkUceIdgANxBuSwFAET766COFhYXp6NGjevPNN8u6OwBKgNtSAADAKszcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABW+X9LfXvwxPbdRgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# use pre in post data to plot graph\n",
    "# Plot demographic parity difference\n",
    "plt.bar(['Demographic Parity Difference'], [metric.disparate_impact()])\n",
    "plt.title('Demographic Parity Difference')\n",
    "plt.show()\n",
    "\n",
    "# Plot equal opportunity difference\n",
    "plt.bar(['Equal Opportunity Difference'], [metric.equal_opportunity_difference()])\n",
    "plt.title('Equal Opportunity Difference')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assume you have three datasets: pre_data, in_data, post_data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Step 1: Calculate Demographic Parity Difference for each dataset\u001b[39;00m\n\u001b[0;32m      7\u001b[0m demographic_parity_differences \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stage, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPre-Processing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn-Processing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPost-Processing\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m---> 10\u001b[0m                           [\u001b[43mpre_data\u001b[49m, in_data, post_data]):\n\u001b[0;32m     11\u001b[0m     metric \u001b[38;5;241m=\u001b[39m ClassificationMetric(\n\u001b[0;32m     12\u001b[0m         original_dataset\u001b[38;5;241m=\u001b[39mpre_data,   \u001b[38;5;66;03m# Original dataset as the baseline\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         classified_dataset\u001b[38;5;241m=\u001b[39mdataset,  \u001b[38;5;66;03m# Predicted dataset at this stage\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         unprivileged_groups\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m}],\n\u001b[0;32m     15\u001b[0m         privileged_groups\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}]\n\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     17\u001b[0m     demographic_parity_differences[stage] \u001b[38;5;241m=\u001b[39m metric\u001b[38;5;241m.\u001b[39mdisparate_impact()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pre_data' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Assume you have three datasets: pre_data, in_data, post_data\n",
    "\n",
    "# Step 1: Calculate Demographic Parity Difference for each dataset\n",
    "demographic_parity_differences = {}\n",
    "\n",
    "for stage, dataset in zip(['Pre-Processing', 'In-Processing', 'Post-Processing'],\n",
    "                          [pre_data, in_data, post_data]):\n",
    "    metric = ClassificationMetric(\n",
    "        original_dataset=pre_data,   # Original dataset as the baseline\n",
    "        classified_dataset=dataset,  # Predicted dataset at this stage\n",
    "        unprivileged_groups=[{'Gender': 0}],\n",
    "        privileged_groups=[{'Gender': 1}]\n",
    "    )\n",
    "    demographic_parity_differences[stage] = metric.disparate_impact()\n",
    "\n",
    "# Step 2: Plot Demographic Parity Difference\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(demographic_parity_differences.keys(), demographic_parity_differences.values(), color='lightgreen')\n",
    "plt.title('Demographic Parity Difference (Disparate Impact) Across Stages')\n",
    "plt.ylabel('Demographic Parity Difference')\n",
    "plt.ylim(0, 2)  # Adjust y-axis limits if necessary\n",
    "plt.axhline(1, color='red', linestyle='--', label='Equality Line (1)')  # Reference line\n",
    "plt.grid(axis='y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Equal Opportunity Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(['Pre Post-processing', 'Post Post-processing'], [equal_opportunity_pre, equal_opportunity_post])\n",
    "plt.title('Equal Opportunity Difference')\n",
    "plt.ylabel('Equal Opportunity Difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Assume you have three datasets: pre_data, in_data, post_data\n",
    "\n",
    "# Step 1: Calculate Equal Opportunity Difference for each dataset\n",
    "equal_opportunity_differences = {}\n",
    "\n",
    "for stage, dataset in zip(['Pre-Processing', 'In-Processing', 'Post-Processing'],\n",
    "                          [pre_data, in_data, post_data]):\n",
    "    metric = ClassificationMetric(\n",
    "        original_dataset=pre_data,   # Original dataset as the baseline\n",
    "        classified_dataset=dataset,  # Predicted dataset at this stage\n",
    "        unprivileged_groups=[{'Gender': 0}],\n",
    "        privileged_groups=[{'Gender': 1}]\n",
    "    )\n",
    "    equal_opportunity_differences[stage] = metric.equal_opportunity_difference()\n",
    "\n",
    "# Step 2: Plot Equal Opportunity Difference\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(equal_opportunity_differences.keys(), equal_opportunity_differences.values(), color='skyblue')\n",
    "plt.title('Equal Opportunity Difference Across Stages')\n",
    "plt.ylabel('Equal Opportunity Difference')\n",
    "plt.ylim(-1, 1)  # Adjust y-axis limits if necessary\n",
    "plt.axhline(0, color='red', linestyle='--', label='Neutrality Line (0)')  # Reference line\n",
    "plt.grid(axis='y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
